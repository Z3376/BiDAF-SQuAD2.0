{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SQuAD4_BiDAF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Z68burAQcmt0",
        "U-Y6eO-dcr2t",
        "-ueD52Nc3zeK",
        "kVER2stLo8yZ",
        "BvMb1vTNn7yb",
        "gQ1Q4W0ftkwU",
        "tT57NWkMw6Kl",
        "n2FT6TIHw9kl"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Z3376/BiDAF-SQuAD2.0/blob/master/SQuAD4_BiDAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thp3Uzv0oJrv",
        "colab_type": "code",
        "outputId": "83f91f9f-6cfd-424a-9d8f-908d81a5ff63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z68burAQcmt0",
        "colab_type": "text"
      },
      "source": [
        "# Terminal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6GJZMmOGxtC",
        "colab_type": "code",
        "outputId": "b07644d9-6337-4910-ecab-b853287547c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%%bash\n",
        "pip install livelossplot\n",
        "pip install keras==2.2.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.6.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.2)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.3.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.16.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (41.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.16.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Y6eO-dcr2t",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebJ9MKj38WT",
        "colab_type": "code",
        "outputId": "0cf764a8-e9e8-4081-a520-bc24f92ea698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from gensim.models import Word2Vec\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.utils import to_categorical\n",
        "import inflect\n",
        "from livelossplot import PlotLossesKeras\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ3wSPYgs7pC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger\n",
        "from keras.layers import AveragePooling1D,TimeDistributed,Bidirectional\n",
        "from keras.layers import MaxPooling1D,RepeatVector,Concatenate\n",
        "from keras.layers import Activation,CuDNNGRU,Multiply\n",
        "from keras.layers import Dropout,Flatten,Permute\n",
        "from keras.layers import Reshape,Lambda,Dense\n",
        "from keras.layers import Input,GRU,Dot,add\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ueD52Nc3zeK",
        "colab_type": "text"
      },
      "source": [
        "# json -> dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsp5jKK08yFK",
        "colab_type": "text"
      },
      "source": [
        "Loading SQuAD2.0 json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkPcLJ-4en7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Returns a dataframe after reading SQuAD2.0 json.\n",
        "\"\"\"\n",
        "def load_data(train_df):\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers_text = []\n",
        "    answers_start = []\n",
        "    for i in range(train_df['data'].shape[0]):\n",
        "        topic = train_df['data'].iloc[i]['paragraphs']\n",
        "        for sub_para in topic:\n",
        "            for q_a in sub_para['qas']:\n",
        "                if(not(q_a['is_impossible'])):\n",
        "                    questions.append(q_a['question'])\n",
        "                    answers_start.append(q_a['answers'][0]['answer_start'])\n",
        "                    answers_text.append(q_a['answers'][0]['text'])\n",
        "                    contexts.append(sub_para['context'])\n",
        "    df = pd.DataFrame({\"contexts\":contexts, \"question\": questions, \"answer_start\": answers_start, \"text\": answers_text})\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xSRBpY4320Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_json('./gdrive/My Drive/squad1.1_train-v2.0.json')\n",
        "df = load_data(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVER2stLo8yZ",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgfV_VeJ4xLz",
        "colab_type": "text"
      },
      "source": [
        "Training Word2Vec embeddings on SQuAD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aIFPgxGNayw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = df.iloc[:,0].drop_duplicates().values\n",
        "question = df.iloc[:,1].drop_duplicates().values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoD-22dOjWbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filters = '!\\'\"#$%&()*+—,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTOsK3QwJE6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_corpus = [text_to_word_sequence(context[i],filters=filters,lower=False) for i in range(len(context))]\n",
        "q_corpus = [text_to_word_sequence(question[i],filters=filters,lower=False) for i in range(len(question))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zAz8uoHpPfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cq_corpus = c_corpus + q_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_XzfpScMhR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cq_corpus.append(['Padding'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNWDzLLPGNAW",
        "colab_type": "code",
        "outputId": "755850b0-f63f-4085-8d66-b3a00d3f38eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "emb_size = 50 \n",
        "emb = Word2Vec(cq_corpus,min_count=1,size=emb_size)\n",
        "emb.save('w2v_squad.model')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvMb1vTNn7yb",
        "colab_type": "text"
      },
      "source": [
        "# Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjSjSzl3dhk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Train-Validation split\n",
        "\"\"\"\n",
        "\n",
        "val_df = df[-int(0.2*df.shape[0]):]\n",
        "df = df[:-int(0.2*df.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRxxhl7xmmaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Return length of longest list given a 2d list\n",
        "\"\"\"\n",
        "def max_len(arr):\n",
        "    max_len = len(arr[0])\n",
        "    for i in range(len(arr)):\n",
        "        if(max_len<len(arr[i])):\n",
        "            max_len = len(arr[i])\n",
        "    return max_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QW3-88gq3ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "pad lists with 'Padding' to have all lists (in a 2d list) of same length\n",
        "\"\"\"\n",
        "def pad(arr,max_len):\n",
        "    for i in range(len(arr)):\n",
        "        if(len(arr[i])!=max_len):\n",
        "            arr[i] += ['Padding']*(max_len-len(arr[i]))\n",
        "    return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tr9l6GLagXah",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function returns start and end indices of answers in the input context paragraph.\n",
        "It'll give correct indices even if answer is 6 and paragraph contains word \"six\" or vice versa.\n",
        "\n",
        "More functionality to be added: Porter stemmer (to get indices if answer is \"six\" but paragraph contains \"sixth\", for example.)\n",
        "\"\"\"\n",
        "\n",
        "def get_ans(corpus,corpus_lower,a_len,debug=False):\n",
        "    \n",
        "    word2num = {'zero':0,\n",
        "            'one':1,\n",
        "            'two':2,\n",
        "            'three':3,\n",
        "            'four':4,\n",
        "            'five':5,\n",
        "            'six':6,\n",
        "            'seven':7,\n",
        "            'eight':8,\n",
        "            'nine':9}\n",
        "    \n",
        "    nw = inflect.engine()\n",
        "    \n",
        "    len_ctr = len(corpus)\n",
        "    \n",
        "    a_start = np.zeros(len_ctr,dtype=int)\n",
        "    a_end = np.zeros(len_ctr,dtype=int)\n",
        "    w_ctr=0\n",
        "\n",
        "    for i in range(len_ctr):\n",
        "        j = 0\n",
        "        l_corpus = len(corpus[i])\n",
        "        n2w_flag = True\n",
        "        w2n_flag = False\n",
        "        a_len_i = text_to_word_sequence(a_len[i],filters=filters)\n",
        "        l_a_len = len(a_len_i)\n",
        "        while(j<l_corpus-l_a_len+1):\n",
        "            if(' '.join([corpus_lower[i][j+k] for k in range(0,l_a_len)])==' '.join(a_len_i)):\n",
        "                a_start[i] = j\n",
        "                a_end[i] = j+l_a_len\n",
        "                break \n",
        "            elif(j==l_corpus-l_a_len):\n",
        "                if(a_len[i].isnumeric() and n2w_flag):\n",
        "                    n2w_flag = False\n",
        "                    a_len_i = text_to_word_sequence(nw.number_to_words(a_len[i]),filters=filters)\n",
        "                    l_a_len = len(a_len_i)\n",
        "                    j = -1\n",
        "                    continue\n",
        "                if(a_len[i] in word2num):\n",
        "                    a_len_i = word2num[a_len[i]]\n",
        "                    try:\n",
        "                        a_start[i] = corpus_lower[j].index(a_len_i)\n",
        "                        a_end[i] = a_start[i]+1\n",
        "                        w2n_flag = True\n",
        "                    except:\n",
        "                        pass\n",
        "                if(not(w2n_flag)):\n",
        "                    w_ctr+=1\n",
        "                    if(debug):\n",
        "                        print(i)\n",
        "                        print('context:',' '.join(corpus_lower[i]))\n",
        "                        print('ans:',a_len[i])\n",
        "                        print('processed ans:',a_len_i)\n",
        "            j+=1\n",
        "    if(debug):\n",
        "        print(w_ctr)\n",
        "        print(w_ctr/len_ctr)\n",
        "    \n",
        "    return a_start,a_end"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRihLtxgs5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Data generator\n",
        "\"\"\"\n",
        "def generator(df,emb,max_q_len,max_c_len,batch_size=256,filters='!\\'\"#$%&()*+—,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
        "    while(True):\n",
        "        batch_df = df.sample(batch_size)\n",
        "        contexts = batch_df.iloc[:,0].values\n",
        "        questions = batch_df.iloc[:,1].values\n",
        "        a_len = batch_df.iloc[:,3].values\n",
        "        \n",
        "        corpus = [text_to_word_sequence(contexts[i],filters=filters,lower=False) for i in range(batch_size)]\n",
        "        corpus_lower = [text_to_word_sequence(contexts[i],filters=filters) for i in range(batch_size)]\n",
        "        q1 = [text_to_word_sequence(questions[i],filters=filters,lower=False) for i in range(batch_size)]\n",
        "        \n",
        "        a_start,a_end = get_ans(corpus,corpus_lower,a_len)\n",
        "        A_start_array = to_categorical(a_start,num_classes=max_c_len)\n",
        "        A_end_array = to_categorical(a_end,num_classes=max_c_len)\n",
        "        \n",
        "        corpus = pad(corpus,max_c_len)\n",
        "        q1 = pad(q1,max_q_len)\n",
        "        \n",
        "        Q_input_array = np.array([[emb[q1[i][j]] for j in range(len(q1[i]))] for i in range(len(q1))])\n",
        "        C_input_array = np.array([[emb[corpus[i][j]] for j in range(max_c_len)] for i in range(len(corpus))])\n",
        "\n",
        "        yield([C_input_array,Q_input_array],A_start_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piGcncq9RlVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch_size = df.shape[0]\n",
        "# batch_df = df.sample(batch_size)\n",
        "# contexts = batch_df.iloc[:,0].values\n",
        "# questions = batch_df.iloc[:,1].values\n",
        "# a_len = batch_df.iloc[:,3].values\n",
        "# # a_start_i = batch_df.iloc[:,2].values\n",
        "\n",
        "# corpus = [text_to_word_sequence(contexts[i],filters=filters,lower=False) for i in range(batch_size)]\n",
        "# corpus_lower = [text_to_word_sequence(contexts[i],filters=filters) for i in range(batch_size)]\n",
        "# q1 = [text_to_word_sequence(questions[i],filters=filters,lower=False) for i in range(batch_size)]\n",
        "\n",
        "# a_start,a_end = get_ans(corpus,corpus_lower,a_len,debug=True)\n",
        "# A_start_array = to_categorical(a_start,num_classes=max_c_len)\n",
        "# A_end_array = to_categorical(a_end,num_classes=max_c_len)\n",
        "\n",
        "# corpus = pad(corpus,max_c_len)\n",
        "# q1 = pad(q1,max_q_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLsrsHPSRqby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t = 262\n",
        "# print(corpus[t][a_start[t]:a_end[t]])\n",
        "# print(a_len[t])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ1Q4W0ftkwU",
        "colab_type": "text"
      },
      "source": [
        "# BiDAF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A4TJ6mzvXJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def softmaxx(x,a):\n",
        "#   return K.softmax(x,axis=a)\n",
        "# def tanhh(x):\n",
        "#   return K.tanh(x)\n",
        "# def addd(x,a):\n",
        "#   return tf.reduce_sum(x,a,keepdims=True)\n",
        "def tile(x,n):\n",
        "  return K.tile(x,n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNkU_zAbMuZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(max_c_len,max_q_len,emb_size,CQ_gru_units=100,gru_units=100):\n",
        "\n",
        "    C_inpt = Input((max_c_len,emb_size),name='Context_Input')\n",
        "    C_encoderGRU = Bidirectional(CuDNNGRU(CQ_gru_units,return_sequences=True,return_state=True))\n",
        "    C_states,C_f_h,C_b_h = C_encoderGRU(C_inpt)\n",
        "    C_states = Lambda(lambda x:K.tanh(x))(C_states)\n",
        "    Q_inpt = Input((max_q_len,emb_size),name='Question_Input')\n",
        "    Q_encoderGRU = Bidirectional(CuDNNGRU(CQ_gru_units,return_sequences=True,return_state=True))\n",
        "    Q_states,Q_f_h,Q_b_h = Q_encoderGRU(Q_inpt)\n",
        "    Q_states = Lambda(lambda x:K.tanh(x))(Q_states)\n",
        "\n",
        "    C_Q = Dot(axes=(-1))([C_states,Q_states])\n",
        "\n",
        "    Q_states_trans = Permute((2,1))(Q_states)\n",
        "    C2Q_attention = Activation('softmax')(C_Q)\n",
        "    Q_attended_states = Dot(axes=(-1))([C2Q_attention,Q_states_trans])\n",
        "    Q2C_attention = MaxPooling1D((max_q_len),data_format='channels_first')(C_Q)\n",
        "    Q2C_attention = Reshape((max_c_len,))(Q2C_attention)\n",
        "    Q2C_attention = Activation('softmax')(Q2C_attention)\n",
        "    Q2C_attention = Reshape((max_c_len,1))(Q2C_attention)\n",
        "    C_attended_states = Dot(axes=(-2))([C_states,Q2C_attention])\n",
        "    C_attended_states = Permute((2,1))(C_attended_states)\n",
        "    C_attended_states_tile = Lambda(tile,arguments={'n':(1,max_c_len,1)})(C_attended_states)\n",
        "\n",
        "    attention = Concatenate()([C_inpt,C_states,C_attended_states_tile,Q_attended_states])\n",
        "\n",
        "    C_attended_states = Reshape((gru_units*2,))(C_attended_states)\n",
        "    attended_states_f = Concatenate()([C_attended_states,C_f_h])\n",
        "    attended_states_f = Dense(gru_units,activation=None)(attended_states_f)\n",
        "    attended_states_b = Concatenate()([C_attended_states,C_b_h])\n",
        "    attended_states_b = Dense(gru_units,activation=None)(attended_states_b)\n",
        "\n",
        "    A = Bidirectional(CuDNNGRU(gru_units,return_sequences=True))(attention,initial_state=[attended_states_f,attended_states_b])\n",
        "    A = Dense(1,activation='tanh')(A)\n",
        "    A = Flatten()(A)\n",
        "    A_start = Dense(max_c_len,activation='softmax',name='start_output')(A)\n",
        "\n",
        "    # A = Concatenate()([A_start,A])\n",
        "    # #A = Dense(1,activation='tanh')(A)\n",
        "    # #A = Flatten()(A)\n",
        "    # A_end = Dense(max_c_len,activation='softmax',name='end_output')(A)\n",
        "\n",
        "    model = Model([C_inpt,Q_inpt],A_start)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Novk8fuFttzk",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF10kLLkt4A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 256\n",
        "max_q_len = max_len(q_corpus)\n",
        "max_c_len = max_len(c_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDFwLichw3Um",
        "colab_type": "text"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SATt9jUJA0d9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = {'start_output':'categorical_crossentropy','end_output':'categorical_crossentropy'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5FXBo4TRcQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_loss_fn(s):\n",
        "  def seq(y_true,y_pred):\n",
        "    y_mul = np.zeros((s,1))\n",
        "    for i in range(s):\n",
        "      y_mul[i] = i\n",
        "    y_mul = K.cast(y_mul,K.floatx())\n",
        "    y_true = K.dot(y_true,y_mul)\n",
        "    y_pred = K.dot(y_pred,y_mul)\n",
        "    #print(K.shape(y_pred))\n",
        "    return K.mean(K.square(y_true-y_pred))\n",
        "  return seq\n",
        "seq_loss = seq_loss_fn(max_c_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBfdVXQ9SF5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_loss_log_fn(s):\n",
        "    def seq(y_true,y_pred):\n",
        "      y_mul = np.zeros((s,1))\n",
        "      for i in range(s):\n",
        "        y_mul[i] = i\n",
        "      y_mul = K.cast(y_mul,K.floatx())\n",
        "      y_true = K.dot(y_true,y_mul)\n",
        "      y_pred = K.dot(y_pred,y_mul)\n",
        "      return K.mean(K.log(K.abs(y_true-y_pred)+1))\n",
        "    return seq\n",
        "seq_loss_log = seq_loss_log_fn(max_c_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT57NWkMw6Kl",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMkgtx_rV4zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adadelta = keras.optimizers.Adadelta(lr=1)\n",
        "adam = keras.optimizers.Adam(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2FT6TIHw9kl",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T6A4dT9Cdc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_acc',mode='max',patience=20,verbose=1,restore_best_weights=True)\n",
        "cp = ModelCheckpoint('squad4.h5',verbose=1)\n",
        "csvl = CSVLogger('squad_log4.csv',separator=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHikB8xjw_fh",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQwYGBDw4Izy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8ecd13fd-0cca-4b49-92f2-a7aa4b6427f5"
      },
      "source": [
        "model = get_model(max_c_len=max_c_len,max_q_len=max_q_len,emb_size=emb_size)\n",
        "# plot_model(get_model(max_c_len,max_q_len),show_shapes=True,to_file='SQUAD2.png')\n",
        "# model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM5sNz5LCWht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "af92ecd0-6c54-4779-d5b8-ee58727ef4d0"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TsNLrqVxEVY",
        "colab_type": "code",
        "outputId": "c4c1baac-c822-4a62-a7af-50996c1c62c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "history = model.fit_generator(generator(df,emb,max_q_len=max_q_len,max_c_len=max_c_len),epochs=epochs,steps_per_epoch=250,validation_data=generator(val_df,emb,max_q_len=max_q_len,max_c_len=max_c_len),validation_steps=60,callbacks=[cp,csvl,PlotLossesKeras()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 23/250 [=>............................] - ETA: 7:47 - loss: 5.6812 - acc: 0.0141"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcH9npLX0vgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log = pd.read_csv('squad_log4.csv')\n",
        "plt.figure()\n",
        "plt.plot(log['loss'])\n",
        "plt.plot(log['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfUj_PQCin0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}